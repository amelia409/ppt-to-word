# å¯¼å…¥å¿…è¦çš„åº“å’Œæ¨¡å—
import os  # æ“ä½œç³»ç»Ÿç›¸å…³åŠŸèƒ½ï¼Œç”¨äºè·å–ç¯å¢ƒå˜é‡
import re  # æ­£åˆ™è¡¨è¾¾å¼åº“ï¼Œç”¨äºæ–‡æœ¬å¤„ç†

# æ ¹æ®é…ç½®åŠ¨æ€å¯¼å…¥æ¨¡å‹SDK
try:
    import google.generativeai as genai  # Google Gemini AIæ¥å£
except ImportError:
    genai = None

try:
    from volcenginesdkarkruntime import Ark  # ç«å±±å¼•æ“å¤§æ¨¡å‹SDK
except ImportError:
    Ark = None

def clean_extracted_text(text: str) -> str:
    """æ¸…ç†å’Œè§„èŒƒåŒ–æå–çš„æ–‡æœ¬ - æ ¹æ®åé¦ˆæ”¹è¿›
    
    å‚æ•°:
        text: éœ€è¦æ¸…ç†çš„åŸå§‹æ–‡æœ¬
        
    è¿”å›:
        æ¸…ç†å’Œè§„èŒƒåŒ–åçš„æ–‡æœ¬
    """
    # åˆ é™¤ç‰¹æ®Šå­—ç¬¦å¹¶è§„èŒƒåŒ–ç©ºæ ¼
    text = re.sub(r'\s+', ' ', text)  # å°†å¤šä¸ªç©ºæ ¼æ›¿æ¢ä¸ºä¸€ä¸ª
    text = re.sub(r'\n\s*\n', '\n\n', text)  # è§„èŒƒåŒ–å¤šä¸ªæ¢è¡Œç¬¦
    text = text.strip()  # å»é™¤é¦–å°¾ç©ºç™½
    
    # åˆ é™¤æ— å…³å’Œè¿‡çŸ­çš„æ–‡æœ¬ç‰‡æ®µ
    lines = text.split('\n')  # æŒ‰è¡Œåˆ†å‰²æ–‡æœ¬
    clean_lines = []  # å­˜å‚¨æ¸…ç†åçš„è¡Œ
    
    for line in lines:
        line = line.strip()  # å»é™¤è¡Œé¦–å°¾ç©ºç™½
        # è¿‡æ»¤è¿‡çŸ­çš„è¡Œï¼ˆå°‘äº15ä¸ªå­—ç¬¦ï¼‰
        if len(line) < 15:
            continue
        # è¿‡æ»¤æ¼”ç¤ºæ–‡ç¨¿ä¸­å¸¸è§çš„é€šç”¨å†…å®¹
        if any(generic in line.lower() for generic in [
            "slide", "é¡µé¢", "ç‚¹å‡»è¿™é‡Œ", "ä¸‹ä¸€é¡µ", "ä¸Šä¸€é¡µ", 
            "èƒŒæ™¯", "æ¨¡æ¿", "è®¾è®¡", "èœå•", "å¯¼èˆª"
        ]):
            continue
        clean_lines.append(line)  # æ·»åŠ æœ‰æ•ˆè¡Œåˆ°ç»“æœåˆ—è¡¨
    
    return '\n'.join(clean_lines)

def generate_explanation(content: str) -> str:
    """æ ¹æ®é…ç½®ä½¿ç”¨AIå¤§æ¨¡å‹ç”Ÿæˆæ ¼å¼åŒ–çš„å­¦æœ¯è§£é‡Š
    
    å‚æ•°:
        content: ä»PPTæˆ–PDFä¸­æå–çš„åŸå§‹å†…å®¹
        
    è¿”å›:
        AIç”Ÿæˆçš„æ ¼å¼åŒ–å­¦æœ¯è§£é‡Šæ–‡æœ¬
    """
    # è·å–æ¨¡å‹ç±»å‹é…ç½®
    model_type = os.getenv('AI_MODEL_TYPE', 'gemini')  # é»˜è®¤ä½¿ç”¨Geminiæ¨¡å‹
    
    # æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©ç›¸åº”çš„API
    if model_type.lower() == 'gemini' and genai is not None:
        # é…ç½®Geminiæ¨¡å‹
        api_key = os.getenv('GEMINI_API_KEY')  # ä»ç¯å¢ƒå˜é‡è·å–APIå¯†é’¥
        if not api_key:
            raise ValueError("ç¯å¢ƒå˜é‡ä¸­æœªè®¾ç½®GEMINI_API_KEY")  # å¦‚æœæœªè®¾ç½®APIå¯†é’¥åˆ™æŠ›å‡ºé”™è¯¯
        
        # ä½¿ç”¨APIå¯†é’¥é…ç½®Gemini
        genai.configure(api_key=api_key)  # é…ç½®APIå¯†é’¥
        model = genai.GenerativeModel('gemini-2.5-flash')  # åˆ›å»ºç”Ÿæˆå¼æ¨¡å‹å®ä¾‹
    elif model_type.lower() == 'volcengine' and Ark is not None:
        # é…ç½®ç«å±±å¼•æ“å¤§æ¨¡å‹
        api_key = os.getenv('ARK_API_KEY')
        model=os.getenv('model_id')  # ä»ç¯å¢ƒå˜é‡è·å–APIå¯†é’¥
        if not api_key:
            raise ValueError("ç¯å¢ƒå˜é‡ä¸­æœªè®¾ç½®ARK_API_KEY")  # å¦‚æœæœªè®¾ç½®APIå¯†é’¥åˆ™æŠ›å‡ºé”™è¯¯
        
        # ä½¿ç”¨APIå¯†é’¥é…ç½®ç«å±±å¼•æ“å¤§æ¨¡å‹
        client = Ark(api_key=api_key)  # åˆ›å»ºç«å±±å¼•æ“å¤§æ¨¡å‹å®¢æˆ·ç«¯
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type} æˆ–æ‰€éœ€SDKæœªå®‰è£…")
    
    # é¦–å…ˆæ¸…ç†å†…å®¹
    clean_content = clean_extracted_text(content)  # æ¸…ç†å’Œè§„èŒƒåŒ–æå–çš„æ–‡æœ¬
    
#     prompt = f"""Eres un experto en crear material didÃ¡ctico acadÃ©mico de alta calidad en ESPAÃ‘OL.

# CONTENIDO A PROCESAR:
# {clean_content}

# INSTRUCCIONES CRÃTICAS PARA EXCELENCIA ACADÃ‰MICA:

# ğŸ“‹ ESTRUCTURA JERÃRQUICA OBLIGATORIA:
# - ## para tÃ­tulos principales temÃ¡ticos (NO por slide, sino por tema)
# - ### para subtemas lÃ³gicos  
# - #### para conceptos especÃ­ficos
# - Reorganiza el contenido lÃ³gicamente, ignorando el orden original de slides
# - Crea una narrativa acadÃ©mica coherente y progresiva

# ğŸš« ELIMINAR ABSOLUTAMENTE:
# - Repeticiones de conceptos bÃ¡sicos ya explicados
# - Frases genÃ©ricas sin valor especÃ­fico del contenido
# - Texto de relleno o artificialmente alargado
# - Contenido fuera del material fuente
# - Explicaciones superficiales

# ğŸ’» CÃ“DIGO (obligatorio si aparece):
# - Explica lÃ­nea por lÃ­nea el funcionamiento
# - Comenta el propÃ³sito en el contexto acadÃ©mico
# - No asumas conocimientos previos no justificados
# - Incluye comentarios explicativos en espaÃ±ol

# ï¿½ ENRIQUECIMIENTO PEDAGÃ“GICO:
# - Tablas comparativas para listas complejas
# - ViÃ±etas (â€¢) para conceptos clave
# - ResÃºmenes al final de secciones importantes
# - Ejercicios prÃ¡cticos relevantes al contenido
# - Preguntas de reflexiÃ³n para consolidar aprendizaje

# âœ… CALIDAD ACADÃ‰MICA:
# - MÃ­nimo 200 palabras por secciÃ³n principal (sin relleno)
# - Profundidad real basada Ãºnicamente en el material fuente
# - EspaÃ±ol formal pero didÃ¡ctico
# - Estructura lÃ³gica que facilite el aprendizaje progresivo
# - Transiciones fluidas entre conceptos

# ğŸ¯ OBJETIVO: Documento profesional, pedagÃ³gicamente sÃ³lido y realmente Ãºtil para el aprendizaje.
# - ProgresiÃ³n lÃ³gica de conceptos simples a complejos
# - Cada pÃ¡rrafo debe aportar valor educativo especÃ­fico

# âŒ PROHIBIDO ESTRICTAMENTE:
# - Contenido genÃ©rico no relacionado con el archivo fuente
# - Repeticiones de conceptos ya cubiertos
# - Frases de relleno sin valor especÃ­fico
# - Explicaciones superficiales de cÃ³digo
# - Desviarse del material original

# FORMATO DE SALIDA REQUERIDO:
# - Documento completamente en espaÃ±ol
# - Estructura clara con tÃ­tulos jerÃ¡rquicos
# - Contenido pedagÃ³gicamente organizado
# - Sin repeticiones innecesarias
# - Enfoque en la comprensiÃ³n profunda del material especÃ­fico

# Genera un documento que sea una referencia acadÃ©mica Ãºtil, completa y pedagÃ³gicamente sÃ³lida basada ÃšNICAMENTE en el contenido proporcionado."""

    prompt = f"""ä½ æ˜¯ä¸€ä¸ªç²¾é€šåˆ›å»ºé«˜è´¨é‡åˆä¸­å­¦ç§‘æ•™å­¦ææ–™çš„ä¸“å®¶ã€‚

å¾…å¤„ç†çš„å†…å®¹ï¼š
{clean_content}

æŒ‡ä»¤ï¼š
ğŸ¯ ç›®æ ‡ï¼šå°†åŸå§‹PPTå†…å®¹è½¬åŒ–ä¸ºä¸€ä¸ªç»“æ„åŒ–ã€ä¸“ä¸šã€ä¸”çœŸæ­£æœ‰ç”¨çš„å­¦ä¹ æ–‡æ¡£ã€‚

ğŸ“‹ ç»“æ„åŒ–ä¸é‡ç»„ï¼š
- ä½¿ç”¨ **##** ä½œä¸ºä¸»è¦ç« èŠ‚æ ‡é¢˜ï¼ˆæŒ‰ä¸»é¢˜åˆ’åˆ†ï¼Œè€ŒéæŒ‰å¹»ç¯ç‰‡åˆ’åˆ†ï¼‰ã€‚
- ä½¿ç”¨ **###** ä½œä¸ºé€»è¾‘å­ä¸»é¢˜ã€‚
- ä½¿ç”¨ **####** ä½œä¸ºå…·ä½“æ¦‚å¿µæˆ–è¦ç‚¹ã€‚
- é€»è¾‘ä¸Šé‡ç»„å†…å®¹ï¼Œåˆ›å»ºä¸€ä¸ªè¿è´¯ã€æ¸è¿›çš„å­¦ä¹ å™è¿°ï¼Œå¿½ç•¥åŸå§‹å¹»ç¯ç‰‡é¡ºåºã€‚

ğŸš« ç»å¯¹ç¦æ­¢ï¼š
- é‡å¤å·²è§£é‡Šè¿‡çš„æ¦‚å¿µã€‚
- æ²¡æœ‰å®è´¨å†…å®¹ã€åªæ˜¯ä¸ºäº†å‡‘å­—æ•°çš„é€šç”¨çŸ­è¯­å’Œå¡«å……è¯ã€‚
- ä»»ä½•è¶…å‡ºæºææ–™èŒƒå›´çš„å†…å®¹ã€‚
- å¯¹æ¦‚å¿µçš„è‚¤æµ…è§£é‡Šã€‚
- åŸå§‹PPTä¸­çš„å¯¼èˆªè¯æ±‡ï¼ˆå¦‚â€œä¸‹ä¸€é¡µâ€ã€â€œç‚¹å‡»è¿™é‡Œâ€ç­‰ï¼‰ã€‚

ğŸ’» ä»£ç ï¼ˆå¦‚æœå‡ºç°ï¼‰ï¼š
- é€è¡Œè¯¦ç»†è§£é‡Šä»£ç çš„åŠŸèƒ½å’Œç›®çš„ã€‚
- è§£é‡Šä»£ç åœ¨æ•´ä¸ªå­¦æœ¯èƒŒæ™¯ä¸­çš„ä½œç”¨ã€‚
- å‡è®¾è¯»è€…æ²¡æœ‰å…ˆéªŒçŸ¥è¯†ï¼Œæä¾›æ¸…æ™°ã€åŸºç¡€çš„è§£é‡Šã€‚
- åœ¨ä»£ç å—ä¸­æ·»åŠ ä¸­æ–‡æ³¨é‡Šã€‚

âœ… å†…å®¹è´¨é‡ä¸æ•™å­¦æ–¹æ³•ï¼š
- æ¯ä¸ªä¸»è¦ç« èŠ‚è‡³å°‘æœ‰200å­—ï¼ˆä¸å«å¡«å……ï¼‰ã€‚
- ç¡®ä¿æ‰€æœ‰å†…å®¹éƒ½åŸºäºä¸”ä»…åŸºäºæä¾›çš„æºææ–™ï¼Œè¿›è¡Œæ·±åº¦åˆ†æå’Œæ‰©å±•ã€‚
- ä½¿ç”¨æ­£å¼ä½†æ˜“äºç†è§£çš„ä¸­æ–‡è¿›è¡Œå†™ä½œã€‚
- é‡‡ç”¨é¡¹ç›®ç¬¦å·ï¼ˆâ€¢ï¼‰ã€åˆ—è¡¨ã€å¯¹æ¯”è¡¨æ ¼æˆ–æ€»ç»“ç­‰å½¢å¼ï¼Œè®©å…³é”®ä¿¡æ¯æ›´æ˜“äºå¸æ”¶ã€‚
- åœ¨ç« èŠ‚æœ«å°¾æ·»åŠ â€œæ€è€ƒé¢˜â€æˆ–â€œå°ç»ƒä¹ â€ï¼Œå¸®åŠ©è¯»è€…å·©å›ºæ‰€å­¦ã€‚

æ ¼å¼è¦æ±‚ï¼š
- æ–‡æ¡£å†…å®¹å¿…é¡»å®Œå…¨ç”¨ä¸­æ–‡ä¹¦å†™ã€‚
- ç»“æ„æ¸…æ™°ï¼Œé‡‡ç”¨åˆ†çº§æ ‡é¢˜ã€‚
- å†…å®¹ç»„ç»‡å…·æœ‰æ•™è‚²é€»è¾‘ã€‚
- æ²¡æœ‰ä¸å¿…è¦çš„é‡å¤ã€‚
- ä¸“æ³¨äºå¯¹ç‰¹å®šå­¦ç§‘å†…å®¹çš„æ·±å…¥ç†è§£ã€‚

è¯·æ ¹æ®ä¸Šè¿°æ‰€æœ‰æŒ‡ä»¤ï¼Œç”Ÿæˆä¸€ä»½åŸºäºæ‰€æä¾›å†…å®¹çš„ï¼Œå®Œæ•´ä¸”æ•™å­¦ä¸¥è°¨çš„å­¦æœ¯å‚è€ƒæ–‡æ¡£ã€‚
"""

    try:
        # æ ¹æ®æ¨¡å‹ç±»å‹è°ƒç”¨ç›¸åº”çš„API
        if model_type.lower() == 'gemini':
            # è°ƒç”¨Geminiæ¨¡å‹ç”Ÿæˆå†…å®¹
            response = model.generate_content(
                prompt,  # æç¤ºè¯
                generation_config=genai.types.GenerationConfig(
                    temperature=0.3,  # è¾ƒä½çš„æ¸©åº¦å€¼ï¼Œä½¿è¾“å‡ºæ›´ä¿å®ˆã€æ›´å¯é¢„æµ‹ï¼Œé€‚åˆå­¦æœ¯å†…å®¹
                    max_output_tokens=2048,  # æœ€å¤§è¾“å‡ºæ ‡è®°æ•°
                    top_p=0.9  # æ§åˆ¶è¾“å‡ºå¤šæ ·æ€§çš„å‚æ•°
                )
            )
            return response.text  # è¿”å›ç”Ÿæˆçš„æ–‡æœ¬
        elif model_type.lower() == 'volcengine':
            # è°ƒç”¨ç«å±±å¼•æ“å¤§æ¨¡å‹ç”Ÿæˆå†…å®¹
            response = client.chat.completions.create(
                model = os.getenv('model_id'),
                messages=[
                    {"role": "user", "content":f"{prompt}"}
                ],
                thinking={"type": "disabled"},
                temperature=0.3,  # è¾ƒä½çš„æ¸©åº¦å€¼ï¼Œä½¿è¾“å‡ºæ›´ä¿å®ˆã€æ›´å¯é¢„æµ‹ï¼Œé€‚åˆå­¦æœ¯å†…å®¹
                top_p=0.9  # æ§åˆ¶è¾“å‡ºå¤šæ ·æ€§çš„å‚æ•°
            )
            return response.choices[0].message.content  # è¿”å›ç”Ÿæˆçš„æ–‡æœ¬
    except Exception as e:
        # é”™è¯¯å¤„ç†æœºåˆ¶
        return f"AIå†…å®¹ç”Ÿæˆé”™è¯¯: {str(e)}\n\nåŸå§‹å†…å®¹:\n{clean_content}"  # è¿”å›é”™è¯¯ä¿¡æ¯å’ŒåŸå§‹å†…å®¹